{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('bus_trafic_clean.csv')\n",
    "df = df.astype({\"horodatage\": \"datetime64\",\n",
    "                \"horodatage_maj\": \"datetime64\",\n",
    "                \"Heure_estimee_de_passage_a_L_arret\": \"datetime64\",\n",
    "                \"date_heure\": \"datetime64\",\n",
    "                \"date\": \"datetime64\",\n",
    "                \"date_heure\": \"datetime64\",\n",
    "                \"numero_de_parc_du_vehicule\": \"category\"\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73941, 62)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample for tests \n",
    "df = df.sample(frac=0.1, random_state=1)\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OKATRA~1\\AppData\\Local\\Temp/ipykernel_11516/1387160799.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_RLM['day'] = (df_RLM['day']) * (1/31)\n",
      "C:\\Users\\OKATRA~1\\AppData\\Local\\Temp/ipykernel_11516/1387160799.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_RLM['month'] = (df_RLM['month'] - 7) * (1/5)\n",
      "C:\\Users\\OKATRA~1\\AppData\\Local\\Temp/ipykernel_11516/1387160799.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_RLM['jour_semaine'] = df_RLM['jour_semaine'].map(Days)\n",
      "C:\\Users\\OKATRA~1\\AppData\\Local\\Temp/ipykernel_11516/1387160799.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_RLM['diff_estimee'] = (\n",
      "C:\\Users\\OKATRA~1\\AppData\\Local\\Temp/ipykernel_11516/1387160799.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_RLM['diff_maj'] = (\n"
     ]
    }
   ],
   "source": [
    "#Sélection des variables\n",
    "df_RLM = df[['date',\n",
    "             'ecart_horaire_en_secondes',\n",
    "             'nom_de_la_ligne',\n",
    "             'etat_SAE_du_vehicule',\n",
    "             'month',\n",
    "             'day',\n",
    "             'jour_semaine',\n",
    "             'OPINION']]\n",
    "\n",
    "# transfo saisonnalité \n",
    "df_RLM['day'] = (df_RLM['day']) * (1/31)\n",
    "df_RLM['month'] = (df_RLM['month'] - 7) * (1/5)\n",
    "Days = {'Lundi': 0, 'Mardi': 1/6, 'Mercredi': 2/6, 'Jeudi': 3/6, 'Vendredi': 4/6, 'Samedi': 5/6, 'Dimanche': 6/6}\n",
    "df_RLM['jour_semaine'] = df_RLM['jour_semaine'].map(Days)\n",
    "\n",
    "# différence en secondes entre l'heure estimée de passage et l'horodatage\n",
    "df_RLM['diff_estimee'] = (\n",
    "    df['Heure_estimee_de_passage_a_L_arret'] - df['horodatage']).dt.total_seconds() / 60\n",
    "\n",
    "# différence en secondes entre l'horodatage et sa mise à jour\n",
    "df_RLM['diff_maj'] = (\n",
    "    df['horodatage_maj'] - df['horodatage']).dt.total_seconds() / 60"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut prédire le trafic le jour suivant, cela implique de grouper nos données par jour.\n",
    "\n",
    "...\n",
    "\n",
    " il y a donc en entrée les données de la veille (voir les données des jours d'avant),\n",
    "\tet en sortie la moyenne des écarts à l'horaire. (puisque les requetes à l'API ne sont pas constantes)\n",
    "\t\n",
    "On ignore donc la saisonnalité journalières et horaires\n",
    "\n",
    "Il y a peu de données, on ne peut donc pas utiliser un LSTM qui aurait été adapté. ( à noter que pour une problématique de prédiction des écarts par bus au cours de la journée, il aurait montré ses qualités)\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nom_de_la_ligne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.512344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nom_de_la_ligne\n",
       "count       126.000000\n",
       "mean         26.166667\n",
       "std           8.512344\n",
       "min           2.000000\n",
       "25%          27.000000\n",
       "50%          29.000000\n",
       "75%          31.000000\n",
       "max          34.000000"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggrégation par jour et par ligne\n",
    "df_group = df_RLM.groupby(['date','nom_de_la_ligne']).agg(\n",
    "    {'ecart_horaire_en_secondes' : 'mean',\n",
    "     'diff_estimee' : 'mean',\n",
    "     'diff_maj' : 'mean',\n",
    "     'month' : 'first',\n",
    "     'day' : 'first',\n",
    "     'jour_semaine' : 'first',\n",
    "     'OPINION' : 'first'\n",
    "    }).merge((df_RLM\n",
    "  .groupby([\"date\",'nom_de_la_ligne', 'etat_SAE_du_vehicule'])\n",
    "  .size()\n",
    "  .unstack('etat_SAE_du_vehicule', fill_value=0)\n",
    "  .add_prefix(\"nombre_etat_\")\n",
    "), on=['date','nom_de_la_ligne'], how='left')\n",
    "\n",
    "# Les valeurs d'écarts prochaines pour chaque ligne\n",
    "df_group['next_ecart'] = df_group.groupby('nom_de_la_ligne')['ecart_horaire_en_secondes'].shift()\n",
    "df_group.dropna(inplace=True)    \n",
    "\n",
    "df_group.reset_index(inplace=True, level=['nom_de_la_ligne'])\n",
    "\n",
    "df_group.groupby(['date']).agg(\n",
    "    {'nom_de_la_ligne' : \"nunique\"}).describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problème : certains jours, il n'y a que très peu de lignes de bus actives. et certaines lignes de bus n'ont que très peu de données.\n",
    "Gardons uniquement les 15 lignes de bus les plus actives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "lignes_keep = df_RLM['nom_de_la_ligne'].value_counts().index[:15]\n",
    "df_group = df_group[df_group['nom_de_la_ligne'].isin(lignes_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 39)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One Hot Encoding\n",
    "df_group = pd.get_dummies(df_group, columns=['OPINION','nom_de_la_ligne'])\n",
    "df_group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ecart_horaire_en_secondes</th>\n",
       "      <th>diff_estimee</th>\n",
       "      <th>diff_maj</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>jour_semaine</th>\n",
       "      <th>nombre_etat_DEV</th>\n",
       "      <th>nombre_etat_DEVP</th>\n",
       "      <th>nombre_etat_HC</th>\n",
       "      <th>nombre_etat_HL</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_de_la_ligne_BOUCHEMAINE &lt;&gt; Z I  EST</th>\n",
       "      <th>nom_de_la_ligne_CIRCULAIRE VERNEAU GARE EUROPE</th>\n",
       "      <th>nom_de_la_ligne_ESPACE ANJOU &lt;&gt; EVENTARD</th>\n",
       "      <th>nom_de_la_ligne_HOPITAL &lt;&gt; MONTREUIL JUIGNE</th>\n",
       "      <th>nom_de_la_ligne_LAC MAINE &lt;&gt; STE GEMMES CL ANJOU</th>\n",
       "      <th>nom_de_la_ligne_M-MARCILLE &lt;&gt; ST AUBIN LA SALLE</th>\n",
       "      <th>nom_de_la_ligne_MURS ERIGNE &lt;&gt; ADEZIERE SALETTE</th>\n",
       "      <th>nom_de_la_ligne_PONTS CE &lt;&gt;  AQUAVITA H. RECULEE</th>\n",
       "      <th>nom_de_la_ligne_ST LEZIN SORGES &lt;&gt; SCHWEITZER</th>\n",
       "      <th>nom_de_la_ligne_ST SYLVAIN BANCHAIS &lt;&gt;TRELAZE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-08-06</th>\n",
       "      <td>106.243902</td>\n",
       "      <td>1.453252</td>\n",
       "      <td>-0.010569</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-06</th>\n",
       "      <td>10.526316</td>\n",
       "      <td>-73.858772</td>\n",
       "      <td>-0.004386</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-06</th>\n",
       "      <td>49.648649</td>\n",
       "      <td>0.791441</td>\n",
       "      <td>-0.005856</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-06</th>\n",
       "      <td>210.698413</td>\n",
       "      <td>0.461111</td>\n",
       "      <td>-0.006349</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-06</th>\n",
       "      <td>39.481481</td>\n",
       "      <td>0.679630</td>\n",
       "      <td>-0.011111</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ecart_horaire_en_secondes  diff_estimee  diff_maj  month  \\\n",
       "date                                                                   \n",
       "2019-08-06                 106.243902      1.453252 -0.010569    0.2   \n",
       "2019-08-06                  10.526316    -73.858772 -0.004386    0.2   \n",
       "2019-08-06                  49.648649      0.791441 -0.005856    0.2   \n",
       "2019-08-06                 210.698413      0.461111 -0.006349    0.2   \n",
       "2019-08-06                  39.481481      0.679630 -0.011111    0.2   \n",
       "\n",
       "                 day  jour_semaine  nombre_etat_DEV  nombre_etat_DEVP  \\\n",
       "date                                                                    \n",
       "2019-08-06  0.193548      0.166667                0                 0   \n",
       "2019-08-06  0.193548      0.166667                0                 0   \n",
       "2019-08-06  0.193548      0.166667                0                 0   \n",
       "2019-08-06  0.193548      0.166667                0                 2   \n",
       "2019-08-06  0.193548      0.166667                1                 0   \n",
       "\n",
       "            nombre_etat_HC  nombre_etat_HL  ...  \\\n",
       "date                                        ...   \n",
       "2019-08-06               0               1  ...   \n",
       "2019-08-06               0               0  ...   \n",
       "2019-08-06               0               0  ...   \n",
       "2019-08-06               0               0  ...   \n",
       "2019-08-06               0               0  ...   \n",
       "\n",
       "            nom_de_la_ligne_BOUCHEMAINE <> Z I  EST  \\\n",
       "date                                                  \n",
       "2019-08-06                                        0   \n",
       "2019-08-06                                        0   \n",
       "2019-08-06                                        0   \n",
       "2019-08-06                                        0   \n",
       "2019-08-06                                        1   \n",
       "\n",
       "            nom_de_la_ligne_CIRCULAIRE VERNEAU GARE EUROPE  \\\n",
       "date                                                         \n",
       "2019-08-06                                               0   \n",
       "2019-08-06                                               0   \n",
       "2019-08-06                                               0   \n",
       "2019-08-06                                               0   \n",
       "2019-08-06                                               0   \n",
       "\n",
       "            nom_de_la_ligne_ESPACE ANJOU <> EVENTARD  \\\n",
       "date                                                   \n",
       "2019-08-06                                         0   \n",
       "2019-08-06                                         0   \n",
       "2019-08-06                                         0   \n",
       "2019-08-06                                         0   \n",
       "2019-08-06                                         0   \n",
       "\n",
       "            nom_de_la_ligne_HOPITAL <> MONTREUIL JUIGNE  \\\n",
       "date                                                      \n",
       "2019-08-06                                            0   \n",
       "2019-08-06                                            0   \n",
       "2019-08-06                                            0   \n",
       "2019-08-06                                            0   \n",
       "2019-08-06                                            0   \n",
       "\n",
       "            nom_de_la_ligne_LAC MAINE <> STE GEMMES CL ANJOU  \\\n",
       "date                                                           \n",
       "2019-08-06                                                 0   \n",
       "2019-08-06                                                 0   \n",
       "2019-08-06                                                 0   \n",
       "2019-08-06                                                 0   \n",
       "2019-08-06                                                 0   \n",
       "\n",
       "            nom_de_la_ligne_M-MARCILLE <> ST AUBIN LA SALLE  \\\n",
       "date                                                          \n",
       "2019-08-06                                                0   \n",
       "2019-08-06                                                0   \n",
       "2019-08-06                                                0   \n",
       "2019-08-06                                                0   \n",
       "2019-08-06                                                0   \n",
       "\n",
       "            nom_de_la_ligne_MURS ERIGNE <> ADEZIERE SALETTE  \\\n",
       "date                                                          \n",
       "2019-08-06                                                0   \n",
       "2019-08-06                                                0   \n",
       "2019-08-06                                                0   \n",
       "2019-08-06                                                0   \n",
       "2019-08-06                                                0   \n",
       "\n",
       "            nom_de_la_ligne_PONTS CE <>  AQUAVITA H. RECULEE  \\\n",
       "date                                                           \n",
       "2019-08-06                                                 0   \n",
       "2019-08-06                                                 0   \n",
       "2019-08-06                                                 0   \n",
       "2019-08-06                                                 0   \n",
       "2019-08-06                                                 0   \n",
       "\n",
       "            nom_de_la_ligne_ST LEZIN SORGES <> SCHWEITZER  \\\n",
       "date                                                        \n",
       "2019-08-06                                              0   \n",
       "2019-08-06                                              0   \n",
       "2019-08-06                                              0   \n",
       "2019-08-06                                              0   \n",
       "2019-08-06                                              0   \n",
       "\n",
       "            nom_de_la_ligne_ST SYLVAIN BANCHAIS <>TRELAZE  \n",
       "date                                                       \n",
       "2019-08-06                                              0  \n",
       "2019-08-06                                              0  \n",
       "2019-08-06                                              0  \n",
       "2019-08-06                                              0  \n",
       "2019-08-06                                              0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_group.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle Prophet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps, essayons de prédire la variable expliqué avec uniquement la variable date. \n",
    "Pour cela, nous allons utiliser le modèle Prophet de Facebook. Ce modèle est basé sur la décomposition de la série temporelle en trois composantes : tendance, saisonnalité et bruit. Il est donc particulièrement adapté à la prédiction de séries temporelles à condition qu'il y ait un lien entre la variable à expliqué et la date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Prophet()\n",
    "\n",
    "df_prophet = df_group['next_ecart'].reset_index()\n",
    "#df_prophet = df_prophet.drop_duplicates(subset='date', keep='first')\n",
    "\n",
    "df_prophet = df_prophet.rename(\n",
    "    columns={'date': 'ds', 'next_ecart': 'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:52:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "22:52:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prophet.forecaster.Prophet at 0x236eee7af10>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train , test = train_test_split(df_prophet, test_size=0.2, random_state=0)\n",
    "m.fit(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utilisés comme indicateurs de performances : MSE, MAE et MAP.\n",
    "Il est important de pouvoir évaluer nos différents modèles de prédiction par rapport à une prédiction naive. \n",
    "\n",
    "Pour réaliser nos prédictions nous avons de nombreuses variables de différents types, de très nombreuses variables qualitatives ainsi qu'une donnée GPS et des dates. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prédiction par la moyenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score :  -0.0025563559317427487\n",
      "mean_squared_error :  4746.572923750909\n",
      "mean_absolute_error :  54.8440815369568\n",
      "mean_absolute_percentage_error 1.6085141991834717\n"
     ]
    }
   ],
   "source": [
    "mean_pred = pd.Series([train['y'].mean()] * len(test))\n",
    "y = test['y']\n",
    "\n",
    "print(\n",
    "    \"r2_score : \", r2_score(y, mean_pred))\n",
    "print(\n",
    "    'mean_squared_error : ', mean_squared_error(y, mean_pred))\n",
    "print(\n",
    "    'mean_absolute_error : ', mean_absolute_error(y, mean_pred))\n",
    "print(\n",
    "    'mean_absolute_percentage_error', mean_absolute_percentage_error(y, mean_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prédiction par modèle Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score :  -0.29990182629457074\n",
      "mean_squared_error :  6154.346113032118\n",
      "mean_absolute_error :  62.920970382232674\n",
      "mean_absolute_percentage_error 1.709110375789912\n"
     ]
    }
   ],
   "source": [
    "predictions = m.predict(test[['ds']])\n",
    "predictions = predictions['yhat']\n",
    "y = test['y']\n",
    "\n",
    "print(\n",
    "    \"r2_score : \", r2_score(y, predictions))\n",
    "print(\n",
    "    'mean_squared_error : ', mean_squared_error(y, predictions))\n",
    "print(\n",
    "    'mean_absolute_error : ', mean_absolute_error(y, predictions))\n",
    "print(\n",
    "    'mean_absolute_percentage_error', mean_absolute_percentage_error(y, predictions))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En comparant les résultats de la prédiction par la moyenne et par le modèle Prophet, on peut voir que le modèle Prophet a des performances excécrables. \n",
    "\n",
    "Cela est dû au fait que l'horodatage ne contient peu ou pas d'information sur la variable à expliqué ou que la connaissance n'est disponible que par combinaisons avec d'autres variables.\n",
    "\n",
    "Continuons dans les modèles explicables avec une régression linéaire multiple qui implique un lien linéaire entre la variable à expliqué et les variables explicatives."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle de Régression linéaire Multiple"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons limité lors du croisement des données, en effet nos données ont été collectés en 2019, il en résulte une incompatibilité avec les données GTFS de parcours des lignes ainsi que les coordonnées des arrêts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain , Xtest , Ytrain , Ytest = train_test_split(df_group.drop('next_ecart', axis=1), df_group['next_ecart'], test_size = 0.2, random_state = 0)\n",
    "\n",
    "collones = df_group.columns.drop('next_ecart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 742)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "poly.fit(Xtrain)\n",
    "Xtrain_poly = poly.transform(Xtrain)\n",
    "Xtest_poly = poly.transform(Xtest)\n",
    "Xtrain_poly.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons essayer de tirer les liens polynomiales entre nos variables et la variable à expliquer par combinaisons de nos variables entre elles et avec elles même. Cependant, il en ressort 742 collones à cause de nos variables qualitative mis en one-hot-encoding. \n",
    "Ce qui détruirait l'explicabilité, alors que cela est l'objectif d'avoir un modèle simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On remets les noms de collones\n",
    "Xtrain = pd.DataFrame(Xtrain, columns= collones)\n",
    "Xtest = pd.DataFrame(Xtest, columns= collones)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons en entrée la matrix Xtrain et un vecteur Ytrain pour chaque variable $X[:, i]$ calculons $\\rho_i = \\frac{(X[:, i] - mean(X[:, i])) * (y - mean(y))}{std(X[:, i]) * std(y)} $ auquel on associe la F-statistique $F_i = \\frac{\\rho_i^2}{1 - \\rho_i^2}*(n-2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleures variables avec p-value: [('ecart_horaire_en_secondes', 220.53481462930077), ('month', 112.72298794660337), ('jour_semaine', 63.78693877278675), ('nombre_etat_LIGN', 35.77269397539561), ('nom_de_la_ligne_ARDENNE <> ROSERAIE', 35.14449799376397), ('nom_de_la_ligne_BELLE BEILLE <> MONPLAISIR', 54.722573969381266), ('nom_de_la_ligne_CIRCULAIRE VERNEAU GARE EUROPE', 36.8186182570096), ('nom_de_la_ligne_ESPACE ANJOU <> EVENTARD', 54.96109961485969), ('nom_de_la_ligne_HOPITAL <> MONTREUIL JUIGNE', 23.592628219527068), ('nom_de_la_ligne_M-MARCILLE <> ST AUBIN LA SALLE', 24.0753360568993)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OkaTravaille\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:302: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# On affiche les 10 variables les plus liés à la variable à expliquer\n",
    "select = SelectKBest(f_regression, k=10)\n",
    "select.fit(Xtrain, Ytrain)\n",
    "\n",
    "features = zip(list(Xtrain.columns[select.get_support(indices=True)]), list(\n",
    "    select.scores_[select.get_support(indices=True)]))\n",
    "print('Meilleures variables avec p-value: %s' % list(features))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque des variables cohérentes avec la variable à estimé. Mais les p-values sont plutot faible, le lien linéaire n'est pas très fort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename des var à l'arrache.\n",
    "X_train = Xtrain \n",
    "X_test = Xtest \n",
    "y_train = Ytrain \n",
    "y_test = Ytest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copie des précédents modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(columns=[\"model\", \"CV\", \"R2\", \"MSE\", \"MAE\", \"MAPE\", \"Temps d'execution\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.2969591273325679\n",
      "MSE:  3328.525873632424\n",
      "MAE:  43.84763702570485\n",
      "MAPE:  1.1314362366377335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OKATRA~1\\AppData\\Local\\Temp/ipykernel_11516/3482457100.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "lr= LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(\"R2: \", r2_score(y_test, y_pred))\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"MAE: \", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MAPE: \", mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "time_end = time.time()\n",
    "\n",
    "tab = [\"lr\", \"false\", r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred), mean_absolute_error(y_test, y_pred), mean_absolute_percentage_error(y_test, y_pred), time_end - time_start]\n",
    "df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5] END copy_X=True, fit_intercept=True, normalize=True;, score=0.384 total time=   0.0s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=True, normalize=True;, score=0.367 total time=   0.0s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=True, normalize=True;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=True, normalize=True;, score=0.277 total time=   0.0s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=True, normalize=True;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=True, normalize=False;, score=0.384 total time=   0.0s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=True, normalize=False;, score=0.367 total time=   0.0s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=True, normalize=False;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=True, normalize=False;, score=0.291 total time=   0.0s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=True, normalize=False;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=False, normalize=True;, score=0.384 total time=   0.0s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=False, normalize=True;, score=0.367 total time=   0.0s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=False, normalize=True;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=False, normalize=True;, score=0.291 total time=   0.0s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=False, normalize=True;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=False, normalize=False;, score=0.384 total time=   0.0s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=False, normalize=False;, score=0.367 total time=   0.0s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=False, normalize=False;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=False, normalize=False;, score=0.291 total time=   0.0s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=False, normalize=False;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END copy_X=False, fit_intercept=True, normalize=True;, score=0.384 total time=   0.0s\n",
      "[CV 2/5] END copy_X=False, fit_intercept=True, normalize=True;, score=0.367 total time=   0.0s\n",
      "[CV 3/5] END copy_X=False, fit_intercept=True, normalize=True;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END copy_X=False, fit_intercept=True, normalize=True;, score=0.277 total time=   0.0s\n",
      "[CV 5/5] END copy_X=False, fit_intercept=True, normalize=True;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END copy_X=False, fit_intercept=True, normalize=False;, score=0.384 total time=   0.0s\n",
      "[CV 2/5] END copy_X=False, fit_intercept=True, normalize=False;, score=0.367 total time=   0.0s\n",
      "[CV 3/5] END copy_X=False, fit_intercept=True, normalize=False;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END copy_X=False, fit_intercept=True, normalize=False;, score=0.291 total time=   0.0s\n",
      "[CV 5/5] END copy_X=False, fit_intercept=True, normalize=False;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END copy_X=False, fit_intercept=False, normalize=True;, score=0.384 total time=   0.0s\n",
      "[CV 2/5] END copy_X=False, fit_intercept=False, normalize=True;, score=0.367 total time=   0.0s\n",
      "[CV 3/5] END copy_X=False, fit_intercept=False, normalize=True;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END copy_X=False, fit_intercept=False, normalize=True;, score=0.291 total time=   0.0s\n",
      "[CV 5/5] END copy_X=False, fit_intercept=False, normalize=True;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END copy_X=False, fit_intercept=False, normalize=False;, score=0.384 total time=   0.0s\n",
      "[CV 2/5] END copy_X=False, fit_intercept=False, normalize=False;, score=0.367 total time=   0.0s\n",
      "[CV 3/5] END copy_X=False, fit_intercept=False, normalize=False;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END copy_X=False, fit_intercept=False, normalize=False;, score=0.291 total time=   0.0s\n",
      "[CV 5/5] END copy_X=False, fit_intercept=False, normalize=False;, score=0.364 total time=   0.0s\n",
      "R2:  0.2969591273325679\n",
      "MSE:  3328.525873632424\n",
      "MAE:  43.84763702570485\n",
      "MAPE:  1.1314362366377335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OKATRA~1\\AppData\\Local\\Temp/ipykernel_11516/3463108573.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "param_grid = {'fit_intercept': [True, False], 'normalize': [True, False], 'copy_X': [True, False]}\n",
    "grid = GridSearchCV(LinearRegression(), param_grid, refit = True, verbose = 3, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "print(\"R2: \", r2_score(y_test, y_pred))\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"MAE: \", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MAPE: \", mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "time_end = time.time()\n",
    "\n",
    "tab = [\"lr_grid\", \"true\", r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred), mean_absolute_error(y_test, y_pred), mean_absolute_percentage_error(y_test, y_pred), time_end - time_start]\n",
    "df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.2987127920302455\n",
      "MSE:  3320.223200847912\n",
      "MAE:  43.82298998164725\n",
      "MAPE:  1.1332837827842692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OKATRA~1\\AppData\\Local\\Temp/ipykernel_11516/3523288223.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred = ridge.predict(X_test)\n",
    "\n",
    "print(\"R2: \", r2_score(y_test, y_pred))\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"MAE: \", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MAPE: \", mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "time_end = time.time()\n",
    "\n",
    "tab = [\"ridge\", \"false\", r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred), mean_absolute_error(y_test, y_pred), mean_absolute_percentage_error(y_test, y_pred), time_end - time_start]\n",
    "df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV 1/5] END alpha=0.1, copy_X=True, fit_intercept=True, normalize=True;, score=0.382 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, copy_X=True, fit_intercept=True, normalize=True;, score=0.365 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, copy_X=True, fit_intercept=True, normalize=True;, score=0.299 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, copy_X=True, fit_intercept=True, normalize=True;, score=0.302 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, copy_X=True, fit_intercept=True, normalize=True;, score=0.365 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, copy_X=True, fit_intercept=True, normalize=False;, score=0.384 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, copy_X=True, fit_intercept=True, normalize=False;, score=0.367 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, copy_X=True, fit_intercept=True, normalize=False;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, copy_X=True, fit_intercept=True, normalize=False;, score=0.291 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, copy_X=True, fit_intercept=True, normalize=False;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, copy_X=True, fit_intercept=False, normalize=True;, score=0.384 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, copy_X=True, fit_intercept=False, normalize=True;, score=0.367 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, copy_X=True, fit_intercept=False, normalize=True;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, copy_X=True, fit_intercept=False, normalize=True;, score=0.291 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, copy_X=True, fit_intercept=False, normalize=True;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, copy_X=True, fit_intercept=False, normalize=False;, score=0.384 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, copy_X=True, fit_intercept=False, normalize=False;, score=0.367 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, copy_X=True, fit_intercept=False, normalize=False;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, copy_X=True, fit_intercept=False, normalize=False;, score=0.291 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, copy_X=True, fit_intercept=False, normalize=False;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, copy_X=False, fit_intercept=True, normalize=True;, score=0.382 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, copy_X=False, fit_intercept=True, normalize=True;, score=0.365 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, copy_X=False, fit_intercept=True, normalize=True;, score=0.299 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, copy_X=False, fit_intercept=True, normalize=True;, score=0.302 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, copy_X=False, fit_intercept=True, normalize=True;, score=0.365 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, copy_X=False, fit_intercept=True, normalize=False;, score=0.384 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, copy_X=False, fit_intercept=True, normalize=False;, score=0.367 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, copy_X=False, fit_intercept=True, normalize=False;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, copy_X=False, fit_intercept=True, normalize=False;, score=0.291 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, copy_X=False, fit_intercept=True, normalize=False;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, copy_X=False, fit_intercept=False, normalize=True;, score=0.384 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, copy_X=False, fit_intercept=False, normalize=True;, score=0.367 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, copy_X=False, fit_intercept=False, normalize=True;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, copy_X=False, fit_intercept=False, normalize=True;, score=0.291 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, copy_X=False, fit_intercept=False, normalize=True;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1, copy_X=False, fit_intercept=False, normalize=False;, score=0.384 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1, copy_X=False, fit_intercept=False, normalize=False;, score=0.367 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1, copy_X=False, fit_intercept=False, normalize=False;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1, copy_X=False, fit_intercept=False, normalize=False;, score=0.291 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1, copy_X=False, fit_intercept=False, normalize=False;, score=0.364 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=True, fit_intercept=True, normalize=True;, score=0.294 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=True, fit_intercept=True, normalize=True;, score=0.309 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=True, fit_intercept=True, normalize=True;, score=0.263 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=True, fit_intercept=True, normalize=True;, score=0.282 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=True, fit_intercept=True, normalize=True;, score=0.304 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=True, fit_intercept=True, normalize=False;, score=0.385 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=True, fit_intercept=True, normalize=False;, score=0.366 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=True, fit_intercept=True, normalize=False;, score=0.295 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=True, fit_intercept=True, normalize=False;, score=0.292 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=True, fit_intercept=True, normalize=False;, score=0.365 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=True, fit_intercept=False, normalize=True;, score=0.385 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=True, fit_intercept=False, normalize=True;, score=0.367 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=True, fit_intercept=False, normalize=True;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=True, fit_intercept=False, normalize=True;, score=0.291 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=True, fit_intercept=False, normalize=True;, score=0.368 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=True, fit_intercept=False, normalize=False;, score=0.385 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=True, fit_intercept=False, normalize=False;, score=0.367 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=True, fit_intercept=False, normalize=False;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=True, fit_intercept=False, normalize=False;, score=0.291 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=True, fit_intercept=False, normalize=False;, score=0.368 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=False, fit_intercept=True, normalize=True;, score=0.294 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=False, fit_intercept=True, normalize=True;, score=0.309 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=False, fit_intercept=True, normalize=True;, score=0.263 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=False, fit_intercept=True, normalize=True;, score=0.282 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=False, fit_intercept=True, normalize=True;, score=0.304 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=False, fit_intercept=True, normalize=False;, score=0.385 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=False, fit_intercept=True, normalize=False;, score=0.366 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=False, fit_intercept=True, normalize=False;, score=0.295 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=False, fit_intercept=True, normalize=False;, score=0.292 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=False, fit_intercept=True, normalize=False;, score=0.365 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=False, fit_intercept=False, normalize=True;, score=0.385 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=False, fit_intercept=False, normalize=True;, score=0.367 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=False, fit_intercept=False, normalize=True;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=False, fit_intercept=False, normalize=True;, score=0.291 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=False, fit_intercept=False, normalize=True;, score=0.368 total time=   0.0s\n",
      "[CV 1/5] END alpha=1, copy_X=False, fit_intercept=False, normalize=False;, score=0.385 total time=   0.0s\n",
      "[CV 2/5] END alpha=1, copy_X=False, fit_intercept=False, normalize=False;, score=0.367 total time=   0.0s\n",
      "[CV 3/5] END alpha=1, copy_X=False, fit_intercept=False, normalize=False;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END alpha=1, copy_X=False, fit_intercept=False, normalize=False;, score=0.291 total time=   0.0s\n",
      "[CV 5/5] END alpha=1, copy_X=False, fit_intercept=False, normalize=False;, score=0.368 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=True, fit_intercept=True, normalize=True;, score=0.078 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=True, fit_intercept=True, normalize=True;, score=0.096 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=True, fit_intercept=True, normalize=True;, score=0.086 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=True, fit_intercept=True, normalize=True;, score=0.094 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=True, fit_intercept=True, normalize=True;, score=0.091 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=True, fit_intercept=True, normalize=False;, score=0.381 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=True, fit_intercept=True, normalize=False;, score=0.352 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=True, fit_intercept=True, normalize=False;, score=0.300 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=True, fit_intercept=True, normalize=False;, score=0.297 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=True, fit_intercept=True, normalize=False;, score=0.369 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=True, fit_intercept=False, normalize=True;, score=0.380 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=True, fit_intercept=False, normalize=True;, score=0.357 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=True, fit_intercept=False, normalize=True;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=True, fit_intercept=False, normalize=True;, score=0.289 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=True, fit_intercept=False, normalize=True;, score=0.385 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=True, fit_intercept=False, normalize=False;, score=0.380 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=True, fit_intercept=False, normalize=False;, score=0.357 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=True, fit_intercept=False, normalize=False;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=True, fit_intercept=False, normalize=False;, score=0.289 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=True, fit_intercept=False, normalize=False;, score=0.385 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=False, fit_intercept=True, normalize=True;, score=0.078 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=False, fit_intercept=True, normalize=True;, score=0.096 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=False, fit_intercept=True, normalize=True;, score=0.086 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=False, fit_intercept=True, normalize=True;, score=0.094 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=False, fit_intercept=True, normalize=True;, score=0.091 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=False, fit_intercept=True, normalize=False;, score=0.381 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=False, fit_intercept=True, normalize=False;, score=0.352 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=False, fit_intercept=True, normalize=False;, score=0.300 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=False, fit_intercept=True, normalize=False;, score=0.297 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=False, fit_intercept=True, normalize=False;, score=0.369 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=False, fit_intercept=False, normalize=True;, score=0.380 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=False, fit_intercept=False, normalize=True;, score=0.357 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=False, fit_intercept=False, normalize=True;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=False, fit_intercept=False, normalize=True;, score=0.289 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=False, fit_intercept=False, normalize=True;, score=0.385 total time=   0.0s\n",
      "[CV 1/5] END alpha=10, copy_X=False, fit_intercept=False, normalize=False;, score=0.380 total time=   0.0s\n",
      "[CV 2/5] END alpha=10, copy_X=False, fit_intercept=False, normalize=False;, score=0.357 total time=   0.0s\n",
      "[CV 3/5] END alpha=10, copy_X=False, fit_intercept=False, normalize=False;, score=0.294 total time=   0.0s\n",
      "[CV 4/5] END alpha=10, copy_X=False, fit_intercept=False, normalize=False;, score=0.289 total time=   0.0s\n",
      "[CV 5/5] END alpha=10, copy_X=False, fit_intercept=False, normalize=False;, score=0.385 total time=   0.0s\n",
      "[CV 1/5] END alpha=100, copy_X=True, fit_intercept=True, normalize=True;, score=0.002 total time=   0.0s\n",
      "[CV 2/5] END alpha=100, copy_X=True, fit_intercept=True, normalize=True;, score=0.008 total time=   0.0s\n",
      "[CV 3/5] END alpha=100, copy_X=True, fit_intercept=True, normalize=True;, score=0.010 total time=   0.0s\n",
      "[CV 4/5] END alpha=100, copy_X=True, fit_intercept=True, normalize=True;, score=0.012 total time=   0.0s\n",
      "[CV 5/5] END alpha=100, copy_X=True, fit_intercept=True, normalize=True;, score=0.005 total time=   0.0s\n",
      "[CV 1/5] END alpha=100, copy_X=True, fit_intercept=True, normalize=False;, score=0.284 total time=   0.0s\n",
      "[CV 2/5] END alpha=100, copy_X=True, fit_intercept=True, normalize=False;, score=0.259 total time=   0.0s\n",
      "[CV 3/5] END alpha=100, copy_X=True, fit_intercept=True, normalize=False;, score=0.251 total time=   0.0s\n",
      "[CV 4/5] END alpha=100, copy_X=True, fit_intercept=True, normalize=False;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END alpha=100, copy_X=True, fit_intercept=True, normalize=False;, score=0.326 total time=   0.0s\n",
      "[CV 1/5] END alpha=100, copy_X=True, fit_intercept=False, normalize=True;, score=0.260 total time=   0.0s\n",
      "[CV 2/5] END alpha=100, copy_X=True, fit_intercept=False, normalize=True;, score=0.263 total time=   0.0s\n",
      "[CV 3/5] END alpha=100, copy_X=True, fit_intercept=False, normalize=True;, score=0.213 total time=   0.0s\n",
      "[CV 4/5] END alpha=100, copy_X=True, fit_intercept=False, normalize=True;, score=0.199 total time=   0.0s\n",
      "[CV 5/5] END alpha=100, copy_X=True, fit_intercept=False, normalize=True;, score=0.376 total time=   0.0s\n",
      "[CV 1/5] END alpha=100, copy_X=True, fit_intercept=False, normalize=False;, score=0.260 total time=   0.0s\n",
      "[CV 2/5] END alpha=100, copy_X=True, fit_intercept=False, normalize=False;, score=0.263 total time=   0.0s\n",
      "[CV 3/5] END alpha=100, copy_X=True, fit_intercept=False, normalize=False;, score=0.213 total time=   0.0s\n",
      "[CV 4/5] END alpha=100, copy_X=True, fit_intercept=False, normalize=False;, score=0.199 total time=   0.0s\n",
      "[CV 5/5] END alpha=100, copy_X=True, fit_intercept=False, normalize=False;, score=0.376 total time=   0.0s\n",
      "[CV 1/5] END alpha=100, copy_X=False, fit_intercept=True, normalize=True;, score=0.002 total time=   0.0s\n",
      "[CV 2/5] END alpha=100, copy_X=False, fit_intercept=True, normalize=True;, score=0.008 total time=   0.0s\n",
      "[CV 3/5] END alpha=100, copy_X=False, fit_intercept=True, normalize=True;, score=0.010 total time=   0.0s\n",
      "[CV 4/5] END alpha=100, copy_X=False, fit_intercept=True, normalize=True;, score=0.012 total time=   0.0s\n",
      "[CV 5/5] END alpha=100, copy_X=False, fit_intercept=True, normalize=True;, score=0.005 total time=   0.0s\n",
      "[CV 1/5] END alpha=100, copy_X=False, fit_intercept=True, normalize=False;, score=0.284 total time=   0.0s\n",
      "[CV 2/5] END alpha=100, copy_X=False, fit_intercept=True, normalize=False;, score=0.259 total time=   0.0s\n",
      "[CV 3/5] END alpha=100, copy_X=False, fit_intercept=True, normalize=False;, score=0.251 total time=   0.0s\n",
      "[CV 4/5] END alpha=100, copy_X=False, fit_intercept=True, normalize=False;, score=0.240 total time=   0.0s\n",
      "[CV 5/5] END alpha=100, copy_X=False, fit_intercept=True, normalize=False;, score=0.326 total time=   0.0s\n",
      "[CV 1/5] END alpha=100, copy_X=False, fit_intercept=False, normalize=True;, score=0.260 total time=   0.0s\n",
      "[CV 2/5] END alpha=100, copy_X=False, fit_intercept=False, normalize=True;, score=0.263 total time=   0.0s\n",
      "[CV 3/5] END alpha=100, copy_X=False, fit_intercept=False, normalize=True;, score=0.213 total time=   0.0s\n",
      "[CV 4/5] END alpha=100, copy_X=False, fit_intercept=False, normalize=True;, score=0.199 total time=   0.0s\n",
      "[CV 5/5] END alpha=100, copy_X=False, fit_intercept=False, normalize=True;, score=0.376 total time=   0.0s\n",
      "[CV 1/5] END alpha=100, copy_X=False, fit_intercept=False, normalize=False;, score=0.260 total time=   0.0s\n",
      "[CV 2/5] END alpha=100, copy_X=False, fit_intercept=False, normalize=False;, score=0.263 total time=   0.0s\n",
      "[CV 3/5] END alpha=100, copy_X=False, fit_intercept=False, normalize=False;, score=0.213 total time=   0.0s\n",
      "[CV 4/5] END alpha=100, copy_X=False, fit_intercept=False, normalize=False;, score=0.199 total time=   0.0s\n",
      "[CV 5/5] END alpha=100, copy_X=False, fit_intercept=False, normalize=False;, score=0.376 total time=   0.0s\n",
      "[CV 1/5] END alpha=1000, copy_X=True, fit_intercept=True, normalize=True;, score=-0.007 total time=   0.0s\n",
      "[CV 2/5] END alpha=1000, copy_X=True, fit_intercept=True, normalize=True;, score=-0.004 total time=   0.0s\n",
      "[CV 3/5] END alpha=1000, copy_X=True, fit_intercept=True, normalize=True;, score=-0.000 total time=   0.0s\n",
      "[CV 4/5] END alpha=1000, copy_X=True, fit_intercept=True, normalize=True;, score=0.001 total time=   0.0s\n",
      "[CV 5/5] END alpha=1000, copy_X=True, fit_intercept=True, normalize=True;, score=-0.006 total time=   0.0s\n",
      "[CV 1/5] END alpha=1000, copy_X=True, fit_intercept=True, normalize=False;, score=0.163 total time=   0.0s\n",
      "[CV 2/5] END alpha=1000, copy_X=True, fit_intercept=True, normalize=False;, score=0.141 total time=   0.0s\n",
      "[CV 3/5] END alpha=1000, copy_X=True, fit_intercept=True, normalize=False;, score=0.167 total time=   0.0s\n",
      "[CV 4/5] END alpha=1000, copy_X=True, fit_intercept=True, normalize=False;, score=0.137 total time=   0.0s\n",
      "[CV 5/5] END alpha=1000, copy_X=True, fit_intercept=True, normalize=False;, score=0.259 total time=   0.0s\n",
      "[CV 1/5] END alpha=1000, copy_X=True, fit_intercept=False, normalize=True;, score=0.054 total time=   0.0s\n",
      "[CV 2/5] END alpha=1000, copy_X=True, fit_intercept=False, normalize=True;, score=0.093 total time=   0.0s\n",
      "[CV 3/5] END alpha=1000, copy_X=True, fit_intercept=False, normalize=True;, score=0.037 total time=   0.0s\n",
      "[CV 4/5] END alpha=1000, copy_X=True, fit_intercept=False, normalize=True;, score=0.005 total time=   0.0s\n",
      "[CV 5/5] END alpha=1000, copy_X=True, fit_intercept=False, normalize=True;, score=0.274 total time=   0.0s\n",
      "[CV 1/5] END alpha=1000, copy_X=True, fit_intercept=False, normalize=False;, score=0.054 total time=   0.0s\n",
      "[CV 2/5] END alpha=1000, copy_X=True, fit_intercept=False, normalize=False;, score=0.093 total time=   0.0s\n",
      "[CV 3/5] END alpha=1000, copy_X=True, fit_intercept=False, normalize=False;, score=0.037 total time=   0.0s\n",
      "[CV 4/5] END alpha=1000, copy_X=True, fit_intercept=False, normalize=False;, score=0.005 total time=   0.0s\n",
      "[CV 5/5] END alpha=1000, copy_X=True, fit_intercept=False, normalize=False;, score=0.274 total time=   0.0s\n",
      "[CV 1/5] END alpha=1000, copy_X=False, fit_intercept=True, normalize=True;, score=-0.007 total time=   0.0s\n",
      "[CV 2/5] END alpha=1000, copy_X=False, fit_intercept=True, normalize=True;, score=-0.004 total time=   0.0s\n",
      "[CV 3/5] END alpha=1000, copy_X=False, fit_intercept=True, normalize=True;, score=-0.000 total time=   0.0s\n",
      "[CV 4/5] END alpha=1000, copy_X=False, fit_intercept=True, normalize=True;, score=0.001 total time=   0.0s\n",
      "[CV 5/5] END alpha=1000, copy_X=False, fit_intercept=True, normalize=True;, score=-0.006 total time=   0.0s\n",
      "[CV 1/5] END alpha=1000, copy_X=False, fit_intercept=True, normalize=False;, score=0.163 total time=   0.0s\n",
      "[CV 2/5] END alpha=1000, copy_X=False, fit_intercept=True, normalize=False;, score=0.141 total time=   0.0s\n",
      "[CV 3/5] END alpha=1000, copy_X=False, fit_intercept=True, normalize=False;, score=0.167 total time=   0.0s\n",
      "[CV 4/5] END alpha=1000, copy_X=False, fit_intercept=True, normalize=False;, score=0.137 total time=   0.0s\n",
      "[CV 5/5] END alpha=1000, copy_X=False, fit_intercept=True, normalize=False;, score=0.259 total time=   0.0s\n",
      "[CV 1/5] END alpha=1000, copy_X=False, fit_intercept=False, normalize=True;, score=0.054 total time=   0.0s\n",
      "[CV 2/5] END alpha=1000, copy_X=False, fit_intercept=False, normalize=True;, score=0.093 total time=   0.0s\n",
      "[CV 3/5] END alpha=1000, copy_X=False, fit_intercept=False, normalize=True;, score=0.037 total time=   0.0s\n",
      "[CV 4/5] END alpha=1000, copy_X=False, fit_intercept=False, normalize=True;, score=0.005 total time=   0.0s\n",
      "[CV 5/5] END alpha=1000, copy_X=False, fit_intercept=False, normalize=True;, score=0.274 total time=   0.0s\n",
      "[CV 1/5] END alpha=1000, copy_X=False, fit_intercept=False, normalize=False;, score=0.054 total time=   0.0s\n",
      "[CV 2/5] END alpha=1000, copy_X=False, fit_intercept=False, normalize=False;, score=0.093 total time=   0.0s\n",
      "[CV 3/5] END alpha=1000, copy_X=False, fit_intercept=False, normalize=False;, score=0.037 total time=   0.0s\n",
      "[CV 4/5] END alpha=1000, copy_X=False, fit_intercept=False, normalize=False;, score=0.005 total time=   0.0s\n",
      "[CV 5/5] END alpha=1000, copy_X=False, fit_intercept=False, normalize=False;, score=0.274 total time=   0.0s\n",
      "R2:  0.30456612634128644\n",
      "MSE:  3292.51076554184\n",
      "MAE:  43.76036719672343\n",
      "MAPE:  1.1539345890429429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OKATRA~1\\AppData\\Local\\Temp/ipykernel_11516/2712223995.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "param_grid = {'alpha': [0.1, 1, 10, 100, 1000], 'fit_intercept': [True, False], 'normalize': [True, False], 'copy_X': [True, False]}\n",
    "grid = GridSearchCV(Ridge(), param_grid, refit = True, verbose = 3, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "print(\"R2: \", r2_score(y_test, y_pred))\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"MAE: \", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MAPE: \", mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "time_end = time.time()\n",
    "\n",
    "tab = [\"ridge_grid\", \"true\", r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred), mean_absolute_error(y_test, y_pred), mean_absolute_percentage_error(y_test, y_pred), time_end - time_start]\n",
    "df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.3891897225577031\n",
      "MSE:  2891.8628935945594\n",
      "MAE:  41.68675298921537\n",
      "MAPE:  0.9637400196020594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OKATRA~1\\AppData\\Local\\Temp/ipykernel_11516/3145534522.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"R2: \", r2_score(y_test, y_pred))\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"MAE: \", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MAPE: \", mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "time_end = time.time()\n",
    "\n",
    "tab = [\"RandomForestRegressor\", \"false\", r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred), mean_absolute_error(y_test, y_pred), mean_absolute_percentage_error(y_test, y_pred), time_end - time_start]\n",
    "df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)\n",
    "\n",
    "Pkl_Filename = \"Model_1_full_regressor.pkl\"  \n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "{'bootstrap': True, 'max_depth': 80, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 200}\n",
      "R2:  0.36183166269988787\n",
      "MSE:  3021.3888054289896\n",
      "MAE:  42.55982814989449\n",
      "MAPE:  1.1614147625279794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OKATRA~1\\AppData\\Local\\Temp/ipykernel_11516/1395810432.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid,\n",
    "                            cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "print(\"R2: \", r2_score(y_test, y_pred))\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"MAE: \", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MAPE: \", mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "time_end = time.time()\n",
    "\n",
    "tab = [\"RandomForestRegressor\", \"true\", r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred), mean_absolute_error(y_test, y_pred), mean_absolute_percentage_error(y_test, y_pred), time_end - time_start]\n",
    "df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  -1.2186674511121594e+23\n",
      "MSE:  5.7697444061681624e+26\n",
      "MAE:  21286156267745.273\n",
      "MAPE:  326333234940.31714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OKATRA~1\\AppData\\Local\\Temp/ipykernel_11516/1390136564.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "sgdr = SGDRegressor().fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgdr.predict(X_test)\n",
    "\n",
    "print(\"R2: \", r2_score(y_test, y_pred))\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"MAE: \", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MAPE: \", mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "time_end = time.time()\n",
    "\n",
    "tab = [\"SGDRegressor\", \"false\", r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred), mean_absolute_error(y_test, y_pred), mean_absolute_percentage_error(y_test, y_pred), time_end - time_start]\n",
    "df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1260 candidates, totalling 3780 fits\n",
      "R2:  0.3253784463790411\n",
      "MSE:  3193.975462077692\n",
      "MAE:  43.15036966686141\n",
      "MAPE:  1.1513421440501064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OKATRA~1\\AppData\\Local\\Temp/ipykernel_11516/3039309171.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# grid search SGDRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'loss': ['huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "    'eta0': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "sgdr = SGDRegressor()\n",
    "grid_search = GridSearchCV(estimator = sgdr, param_grid = param_grid,\n",
    "                            cv = 3, n_jobs = -1, verbose = 2)\n",
    "    \n",
    "grid_search.fit(X_train, y_train)\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "print(\"R2: \", r2_score(y_test, y_pred))\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"MAE: \", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MAPE: \", mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "time_end = time.time()\n",
    "\n",
    "tab = [\"SGDRegressor\", \"true\", r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred), mean_absolute_error(y_test, y_pred), mean_absolute_percentage_error(y_test, y_pred), time_end - time_start]\n",
    "df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.2217601392447387\n",
      "MSE:  3684.553221760332\n",
      "MAE:  45.49565690973741\n",
      "MAPE:  1.1560683330668629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OKATRA~1\\AppData\\Local\\Temp/ipykernel_11516/129790176.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter=1000, random_state=42)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "print(\"R2: \", r2_score(y_test, y_pred))\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"MAE: \", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MAPE: \", mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "time_end = time.time()\n",
    "\n",
    "tab = [\"MLPRegressor\", \"false\", r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred), mean_absolute_error(y_test, y_pred), mean_absolute_percentage_error(y_test, y_pred), time_end - time_start]\n",
    "df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "R2:  0.1590477448876796\n",
      "MSE:  3981.4631672986675\n",
      "MAE:  48.88192704503004\n",
      "MAPE:  1.2766710536999524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OKATRA~1\\AppData\\Local\\Temp/ipykernel_11516/2591508133.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "param_grid = {'hidden_layer_sizes': [(100, 100, 100), (100, 100, 100, 100), (100, 100, 100, 100, 100)],\n",
    "                'max_iter': [1000, 2000, 3000],\n",
    "                'random_state': [42]}\n",
    "grid = GridSearchCV(MLPRegressor(), param_grid, refit=True, verbose=3, n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "print(\"R2: \", r2_score(y_test, y_pred))\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"MAE: \", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MAPE: \", mean_absolute_percentage_error(y_test, y_pred))\n",
    "\n",
    "time_end = time.time()\n",
    "\n",
    "tab = [\"MLPRegressor\", \"true\", r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred), mean_absolute_error(y_test, y_pred), mean_absolute_percentage_error(y_test, y_pred), time_end - time_start]\n",
    "df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OKATRA~1\\AppData\\Local\\Temp/ipykernel_11516/1246070978.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "mean_pred = pd.Series([y_train.mean()] * len(y_test))\n",
    "\n",
    "tab = [\"Mean\", \"false\", r2_score(y, mean_pred), mean_squared_error(y, mean_pred), mean_absolute_error(y, mean_pred), mean_absolute_percentage_error(y, mean_pred), 0]\n",
    "df_result = df_result.append(pd.Series(tab, index=df_result.columns), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[\"Temps d'execution\"] = df_result[\"Temps d'execution\"].apply(lambda x: round(x, 2))\n",
    "\n",
    "# export result to csv\n",
    "df_result.to_csv(\"result.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>CV</th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>Temps d'execution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>false</td>\n",
       "      <td>2.969591e-01</td>\n",
       "      <td>3.328526e+03</td>\n",
       "      <td>4.384764e+01</td>\n",
       "      <td>1.131436e+00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lr_grid</td>\n",
       "      <td>true</td>\n",
       "      <td>2.969591e-01</td>\n",
       "      <td>3.328526e+03</td>\n",
       "      <td>4.384764e+01</td>\n",
       "      <td>1.131436e+00</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ridge</td>\n",
       "      <td>false</td>\n",
       "      <td>2.987128e-01</td>\n",
       "      <td>3.320223e+03</td>\n",
       "      <td>4.382299e+01</td>\n",
       "      <td>1.133284e+00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ridge_grid</td>\n",
       "      <td>true</td>\n",
       "      <td>3.045661e-01</td>\n",
       "      <td>3.292511e+03</td>\n",
       "      <td>4.376037e+01</td>\n",
       "      <td>1.153935e+00</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>false</td>\n",
       "      <td>3.891897e-01</td>\n",
       "      <td>2.891863e+03</td>\n",
       "      <td>4.168675e+01</td>\n",
       "      <td>9.637400e-01</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>true</td>\n",
       "      <td>3.618317e-01</td>\n",
       "      <td>3.021389e+03</td>\n",
       "      <td>4.255983e+01</td>\n",
       "      <td>1.161415e+00</td>\n",
       "      <td>79.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>false</td>\n",
       "      <td>-1.218667e+23</td>\n",
       "      <td>5.769744e+26</td>\n",
       "      <td>2.128616e+13</td>\n",
       "      <td>3.263332e+11</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SGDRegressor</td>\n",
       "      <td>true</td>\n",
       "      <td>3.253784e-01</td>\n",
       "      <td>3.193975e+03</td>\n",
       "      <td>4.315037e+01</td>\n",
       "      <td>1.151342e+00</td>\n",
       "      <td>11.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>false</td>\n",
       "      <td>2.217601e-01</td>\n",
       "      <td>3.684553e+03</td>\n",
       "      <td>4.549566e+01</td>\n",
       "      <td>1.156068e+00</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>true</td>\n",
       "      <td>1.590477e-01</td>\n",
       "      <td>3.981463e+03</td>\n",
       "      <td>4.888193e+01</td>\n",
       "      <td>1.276671e+00</td>\n",
       "      <td>25.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>true</td>\n",
       "      <td>-2.556356e-03</td>\n",
       "      <td>4.746573e+03</td>\n",
       "      <td>5.484408e+01</td>\n",
       "      <td>1.608514e+00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mean</td>\n",
       "      <td>false</td>\n",
       "      <td>-2.556356e-03</td>\n",
       "      <td>4.746573e+03</td>\n",
       "      <td>5.484408e+01</td>\n",
       "      <td>1.608514e+00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model     CV            R2           MSE           MAE  \\\n",
       "0                      lr  false  2.969591e-01  3.328526e+03  4.384764e+01   \n",
       "1                 lr_grid   true  2.969591e-01  3.328526e+03  4.384764e+01   \n",
       "2                   ridge  false  2.987128e-01  3.320223e+03  4.382299e+01   \n",
       "3              ridge_grid   true  3.045661e-01  3.292511e+03  4.376037e+01   \n",
       "4   RandomForestRegressor  false  3.891897e-01  2.891863e+03  4.168675e+01   \n",
       "5   RandomForestRegressor   true  3.618317e-01  3.021389e+03  4.255983e+01   \n",
       "6            SGDRegressor  false -1.218667e+23  5.769744e+26  2.128616e+13   \n",
       "7            SGDRegressor   true  3.253784e-01  3.193975e+03  4.315037e+01   \n",
       "8            MLPRegressor  false  2.217601e-01  3.684553e+03  4.549566e+01   \n",
       "9            MLPRegressor   true  1.590477e-01  3.981463e+03  4.888193e+01   \n",
       "10           MLPRegressor   true -2.556356e-03  4.746573e+03  5.484408e+01   \n",
       "11                   Mean  false -2.556356e-03  4.746573e+03  5.484408e+01   \n",
       "\n",
       "            MAPE  Temps d'execution  \n",
       "0   1.131436e+00               0.01  \n",
       "1   1.131436e+00               0.15  \n",
       "2   1.133284e+00               0.01  \n",
       "3   1.153935e+00               0.66  \n",
       "4   9.637400e-01               0.56  \n",
       "5   1.161415e+00              79.52  \n",
       "6   3.263332e+11               0.02  \n",
       "7   1.151342e+00              11.20  \n",
       "8   1.156068e+00               1.39  \n",
       "9   1.276671e+00              25.01  \n",
       "10  1.608514e+00               0.00  \n",
       "11  1.608514e+00               0.00  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c82e4ef8f8188b96c61e38a6d616e25501428783ccaa177295abba884367e3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
